# SRE Agent

> AutoGen-powered multi-agent system for intelligent Kubernetes SRE operations.

## Quick Start

```bash
# 1. Setup Environment
cd agent
python -m venv venv && source venv/bin/activate
pip install -e ".[dev,azure]"

# 2. Configure Settings
cp .env.example .env
# Edit .env: Set AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_KEY, KUBECONFIG

# 3. Start Development Server
python dev.py
# â†’ http://localhost:8000 (API) + AutoGen multi-agent workflow ready
# â†’ http://localhost:8000/docs (Interactive API Documentation)
# â†’ http://localhost:8000/redoc (Alternative API Docs)

# 4. Test the Multi-Agent System
curl -X POST http://localhost:8000/decide \
  -H "Content-Type: application/json" \
  -d '{"event_type": "Warning", "namespace": "default", "resource_name": "test-pod", "resource_kind": "Pod", "event_data": {}}'
```

## Architecture

**AutoGen GroupChat Workflow**: Multi-agent collaboration for intelligent SRE operations.

```
K8s Event â†’ SREWorkflow (GroupChat) â†’ Decision/Actions
              â†“
    ğŸ” Analysis Agent (diagnoses with K8s tools)
              â†“
    ğŸ’¡ Recommendation Agent (suggests actions)
              â†“
    ğŸ›¡ï¸ Guard Agent (validates safety)
              â†“
    âœ… Approval Agent (makes final decision)
              â†“
    âš¡ Execution Agent (implements actions)
```

### Key Components

- **SREWorkflow**: Business logic layer managing multi-agent workflows
- **GroupChatManager**: AutoGen's native orchestrator for agent conversations
- **KubernetesTools**: Real K8s API integration with function calling
- **Analysis Agent**: Pattern matching and symptom correlation with evidence
- **Multi-Agent Decision**: Collaborative reasoning through structured conversations
- **Safety-First**: Dry-run mode, human approval, and action validation

## Configuration

### Environment Variables

**Required:**
- `AZURE_OPENAI_ENDPOINT` + `AZURE_OPENAI_API_KEY` (Azure OpenAI)
- OR `OPENAI_API_KEY` (OpenAI)
- `KUBECONFIG` (Kubernetes config path)

**Optional:**
- `PROMETHEUS_URL` - Metrics integration
- `AZURE_KEY_VAULT_URL` - Secure secret management
- `ENABLE_DRY_RUN=true` - Safety mode (default)
- `REQUIRE_HUMAN_APPROVAL=true` - Human-in-the-loop (default)

### AutoGen Configuration

The workflow is configured through environment variables and code:

**LLM Settings**: Configured in `src/config.py` with model selection per agent
**Agent Behavior**: Defined in `src/workflows/sre_workflow.py` using GroupChatManager
**Tool Registration**: Kubernetes tools auto-registered with function calling
**Safety Guards**: Built into workflow logic and tool execution

Example agent config in `configs/agents.yaml.example`:
```yaml
workflow:
  max_turns: 10
  timeout_seconds: 300
  require_consensus: true
  human_in_loop_actions:
    - "delete_resources"
    - "scale_down_critical"
```

## API Documentation

### Interactive Documentation (FastAPI)

When running the development server, FastAPI automatically provides interactive API documentation:

- **Swagger UI**: http://localhost:8000/docs
  - Interactive API testing interface
  - Request/response examples
  - Schema validation

- **ReDoc**: http://localhost:8000/redoc
  - Clean, readable API documentation
  - Generated from OpenAPI schema

### API Endpoints

- `GET /health` - Health check
- `POST /decide` - Multi-agent decision endpoint (called by K8s Operator)
- `POST /execute` - Action execution with safety guards

### Example Usage

```bash
# Health check
curl http://localhost:8000/health

# Decision request (simulates K8s Operator call)
curl -X POST http://localhost:8000/decide \
  -H "Content-Type: application/json" \
  -d '{
    "event_type": "Warning",
    "namespace": "production",
    "resource_name": "web-app",
    "resource_kind": "Pod",
    "event_data": {"reason": "FailedMount", "message": "Volume mount failed"}
  }'
```

**ğŸ’¡ Tip**: Use the interactive docs at http://localhost:8000/docs to:
- Test API endpoints with a web interface
- See request/response schemas
- Understand the AutoGen multi-agent workflow
- View real-time validation and examples

**Response**: Multi-agent analysis with decision, confidence, and recommended actions.

## Development

### Install & Run
```bash
# Install with dev dependencies
pip install -e ".[dev,azure]"

# Development server with hot reload + debug logs
python dev.py
# âœ… API: http://localhost:8000
# âœ… Docs: http://localhost:8000/docs (Swagger UI)
# âœ… Docs: http://localhost:8000/redoc (ReDoc)

# Or direct API start (production mode)
python -m src.api.main
```

### Testing
```bash
# Run all tests
pytest --cov=src tests/

# Test specific components
pytest tests/test_sre_workflow.py -v
pytest tests/test_kubernetes_tools.py -v
```

### Code Quality
```bash
# Format and lint
black src/ && ruff check src/ --fix

# Type checking
mypy src/

# Pre-commit hooks
pre-commit install && pre-commit run --all-files
```

### AutoGen Development Guide

ì´ í”„ë¡œì íŠ¸ëŠ” **AutoGen í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì¡°**ë¥¼ ì‚¬ìš©í•œ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. v0.2 í˜¸í™˜ì„±ê³¼ ìµœì‹  0.7.4+ ê¸°ëŠ¥ì„ í•¨ê»˜ í™œìš©í•©ë‹ˆë‹¤.

#### AutoGen íŒ¨í‚¤ì§€ êµ¬ì¡°

**ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€:**
- `pyautogen` - v0.2 í˜¸í™˜ API (ê¸°ì¡´ GroupChat, AssistantAgent ë“±)
- `autogen-agentchat` - ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ (0.7.4+)
- `autogen-ext[openai]` - ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸ì™€ í™•ì¥ ê¸°ëŠ¥

#### AutoGen í•µì‹¬ ê°œë…

AutoGenì—ì„œëŠ” **"Orchestrator"ë¼ëŠ” ê³µì‹ ìš©ì–´ê°€ ì—†ìŠµë‹ˆë‹¤**. ëŒ€ì‹  ë‹¤ìŒ êµ¬ì¡°ë¥¼ ì‚¬ìš©:

```python
# 1. v0.2 ìŠ¤íƒ€ì¼ (ì•ˆì •ì , ê²€ì¦ë¨)
from autogen import GroupChat, GroupChatManager, AssistantAgent

# 2. v0.7.4+ ìŠ¤íƒ€ì¼ (ìµœì‹  ê¸°ëŠ¥)
from autogen_agentchat.agents import AssistantAgent as NewAssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient

# 3. í•˜ì´ë¸Œë¦¬ë“œ Workflow (ì¶”ì²œ)
class SREWorkflow:
    def __init__(self):
        self.agents = self._create_agents()      # v0.2 í˜¸í™˜
        self.group_chat = self._create_group_chat()  # v0.2 ì•ˆì •ì„±
        self.manager = self._create_manager()    # GroupChatManager
    
    def _create_manager(self) -> GroupChatManager:
        return GroupChatManager(
            groupchat=self.group_chat,
            llm_config={"model": "gpt-4", "temperature": 0.0}
        )
```#### ì—ì´ì „íŠ¸ ì‘ì„± íŒ¨í„´ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹)

**v0.2 í˜¸í™˜ ë°©ì‹** (í˜„ì¬ ì‚¬ìš©, ì•ˆì •ì ):
```python
from autogen import ConversableAgent

class AnalysisAgent(ConversableAgent):
    def __init__(self, name: str, **kwargs):
        super().__init__(name=name, system_message="...", **kwargs)
        
        # v0.2 ë„êµ¬ ë“±ë¡ íŒ¨í„´
        self.register_for_llm(name="get_pod_status")(self.k8s_tools.get_pod_status)
        self.register_for_execution(name="get_pod_status")(self.k8s_tools.get_pod_status)
```

**v0.7.4+ ìµœì‹  ë°©ì‹** (í–¥í›„ ì „í™˜):
```python
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient

class ModernAnalysisAgent(AssistantAgent):
    def __init__(self, name: str, **kwargs):
        model_client = OpenAIChatCompletionClient(model="gpt-4")
        super().__init__(name=name, model_client=model_client, **kwargs)
        
        # ìƒˆë¡œìš´ ë„êµ¬ ë“±ë¡ ë°©ì‹ (0.7.4+)
```

#### ë„êµ¬(Tools) ì‘ì„± íŒ¨í„´

**íƒ€ì… ì–´ë…¸í…Œì´ì…˜ í•„ìˆ˜** (AutoGen function calling):
```python
from typing import Annotated

async def get_pod_status(
    namespace: Annotated[str, "Kubernetes namespace"],
    pod_name: Annotated[str, "Pod name to check"] | None = None,
) -> dict[str, Any]:
    """
    Get pod status information.

    Args:
        namespace: Kubernetes namespace
        pod_name: Specific pod name (optional)

    Returns:
        Pod status information
    """
    # êµ¬í˜„...
```

#### ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ íŒ¨í„´ (AutoGen 0.7.4+)

**ë¹„ë™ê¸° ì²˜ë¦¬ + ìƒˆë¡œìš´ GroupChat ê¸°ëŠ¥**:
```python
async def process_incident(self, event_data: dict) -> dict:
    initial_message = f"ë¶„ì„í•´ì£¼ì„¸ìš”: {event_data}"

    # AutoGen 0.7.4+ GroupChat ì„¤ì •
    group_chat = GroupChat(
        agents=list(self.agents.values()),
        messages=[],
        max_round=10,
        speaker_selection_method="auto",
        allow_repeat_speaker=False,  # ìƒˆë¡œìš´ ê¸°ëŠ¥
        send_introductions=True,     # ì—ì´ì „íŠ¸ ì†Œê°œ
    )

    result = await self.manager.a_initiate_chat(
        self.agents["analysis"],
        message=initial_message,
        max_turns=10
    )

    return self._extract_decision(result)
```

#### ê°œë°œ ì‹œ ì£¼ì˜ì‚¬í•­ (í•˜ì´ë¸Œë¦¬ë“œ í™˜ê²½)

1. **íŒ¨í‚¤ì§€ ì„ íƒ**: v0.2 í˜¸í™˜(`autogen`) vs ì‹ ë²„ì „(`autogen-agentchat`) êµ¬ë¶„
2. **Function Calling**: `Annotated` íƒ€ì… íŒíŠ¸ í•„ìˆ˜ (ë‘ ë²„ì „ ê³µí†µ)
3. **Model Client**: ì‹ ë²„ì „ì€ `OpenAIChatCompletionClient` ë“± ëª…ì‹œì  í´ë¼ì´ì–¸íŠ¸ í•„ìš”
4. **Error Handling**: ë²„ì „ë³„ë¡œ ë‹¤ë¥¸ ì˜ˆì™¸ ì²˜ë¦¬ íŒ¨í„´
5. **Async/Await**: ëª¨ë“  LLM í˜¸ì¶œì€ ë¹„ë™ê¸° ê¶Œì¥
6. **Message History**: GroupChatì´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ìë™ ê´€ë¦¬
7. **Migration Path**: v0.2 â†’ v0.7.4+ ì ì§„ì  ì „í™˜ ê°€ëŠ¥

#### ë””ë²„ê¹… íŒ

```python
# 1. ì—ì´ì „íŠ¸ ëŒ€í™” ë¡œê·¸ í™•ì¸
import structlog
logger = structlog.get_logger()

# 2. ê°œë°œ ëª¨ë“œì—ì„œ mock ì‚¬ìš©
if self.settings.development.mock_k8s_api:
    return self._mock_pod_status(namespace, pod_name)

# 3. GroupChat ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê²€ì‚¬
print(f"Messages: {self.group_chat.messages}")
```

### Project Structure
```
src/
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ sre_workflow.py     # AutoGen GroupChat workflow
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ analysis.py         # K8s issue analysis agent
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ kubernetes.py       # K8s API integration
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py            # FastAPI endpoints
â”œâ”€â”€ guards/                 # Safety mechanisms (empty)
â”œâ”€â”€ config.py              # Pydantic settings
â””â”€â”€ __init__.py

configs/
â”œâ”€â”€ agents.yaml.example    # Agent configuration template
â””â”€â”€ README.md              # Configuration guide

dev.py                     # Development server
pyproject.toml            # Project dependencies & config
.env.example              # Environment template
```
